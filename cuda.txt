CUDA  Compute Unified Device Architecture

A CUDA program is a unified source code encompassing both host and device code 

The NVIDIA C compiler (nvcc) separates the two during the compilation process and host code is straight ANSI C code

The execution starts with host (CPU) execution. When a kernel function is invoked, the execution is moved to a device (GPU), where a large number of threads are
generated to take advantage of rich data parallelism

KernelFunc<<<nBlk,nThrds>>>(args)

#include<cuda.h>
_ _global_ _ void add(int *a, int *b, int *c)
{
   int i=threadIdx.x;
   c[i] = a[i]+b[i];
}

int main(void)
{
   int a[3] = {1,2,3}, b[3]={1,2,3}, c;// host copies of variables a, b & c
   int *d_a, *d_b, *d_c; // device copies of variables a, b & c
   int size = 3*sizeof(int);
   cudaMalloc((void **)&d_a, size);
   cudaMalloc((void **)&d_b, size);
   cudaMalloc((void **)&d_c, size);
   // Copy inputs to device
   cudaMemcpy(d_a, &a, size, cudaMemcpyHostToDevice);
   cudaMemcpy(d_b, &b, size, cudaMemcpyHostToDevice);
   // Launch add() kernel on GPU
   add<<<1,n>>>(d_a, d_b, d_c);
   // Copy result back to host
   cudaMemcpy(&c, d_c, size, cudaMemcpyDeviceToHost);
   // Cleanup
   cudaFree(d_a);
   cudaFree(d_b);
   cudaFree(d_c);
   return 0;
}

__device__  both exec in device
__global__  host callable device exec
__host__  both callable and exec in host

dim3 dimGrid(1,1,1)
dim3 dimBlock(n,n,1)
MatrixMul<<<dimGrid,dimBlock>>>(d_a,d_b,d_c)

int i = threadIdx.x + blockIdx.x*blockDim.x;
int j = threadIdx.y + blockIdx.y*blockDim.y;

Number of blocks = 128 (N)  32 threads in each block (blk size M)

5 Blk 3rd thread ID = 32*5 + 3 = 163  

  cudaEvent_t start, stop; // using cuda events to measure time
float elapsed_time_ms;
  cudaEventCreate( &start );
cudaEventCreate( &stop );
  cudaEventRecord( start, 0 ); // instrument code to measure start time
vectorAdd<<<B,T>>>(dev_a,dev_b,dev_c);
cudaMemcpy(c,dev_c, N*sizeof(int), cudaMemcpyDeviceToHost);
  cudaEventRecord( stop, 0 ); // instrument code to measure end time
  cudaEventSynchronize( stop);
  cudaEventElapsedTime( &elapsed_time_ms, start, stop );
  printf("Time to calculate results: %f ms.\n", elapsed_time_ms);
  
  
cudaError_t cudaStatus = cudaMalloc((void**)&dev_c, size * sizeof(int));
if (cudaStatus != cudaSuccess)
{
fprintf(stderr, "cudaMalloc failed!");
}

cudaError_t error = cudaGetLastError();

1D Grid 1D blk  block and thread arranged in 1D
1D Grid 2D blk  block in 1D and thread in arraged 2D within blk
2D Grid 1D blk  block arranged 2D within grid and 1D within blk 
